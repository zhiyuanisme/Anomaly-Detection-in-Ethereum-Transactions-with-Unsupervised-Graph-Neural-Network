import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pickle
import os
import json
from datetime import datetime
import base64
from io import BytesIO
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ¯ GraphSAGEå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    .status-success {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 0.75rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .status-warning {
        background: #fff3cd;
        border: 1px solid #ffeaa8;
        color: #856404;
        padding: 0.75rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .status-error {
        background: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 0.75rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ä¸»æ ‡é¢˜
st.markdown("""
<div class="main-header">
    <h1>ğŸ¯ GraphSAGE + AutoEncoder + OCSVM å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ</h1>
    <p>æ— ç›‘ç£å›¾ç¥ç»ç½‘ç»œå¼‚å¸¸æ£€æµ‹ | Top-Kæ€§èƒ½åˆ†æ | æ··æ·†çŸ©é˜µå¯è§†åŒ–</p>
</div>
""", unsafe_allow_html=True)

# ä¾§è¾¹æ é…ç½®
st.sidebar.header("ğŸ”§ ç³»ç»Ÿé…ç½®")

# æ•°æ®è·¯å¾„é…ç½®
data_paths = {
    "è®­ç»ƒæ•°æ®ç›®å½•": "dataset_k-hop2/",
    "ç»“æœä¿å­˜ç›®å½•": "quick_ocsvm_results/",
    "æ¨¡å‹ä¿å­˜ç›®å½•": "graphsage_autoencoder_models/"
}

st.sidebar.subheader("ğŸ“‚ æ•°æ®è·¯å¾„")
for name, path in data_paths.items():
    st.sidebar.text_input(name, value=path, key=f"path_{name}")

# æ¨¡å‹å‚æ•°é…ç½®
st.sidebar.subheader("ğŸ›ï¸ æ¨¡å‹å‚æ•°")
ocsvm_nu = st.sidebar.slider("OCSVM Nuå‚æ•°", 0.01, 0.2, 0.05, 0.01)
ocsvm_kernel = st.sidebar.selectbox("OCSVMæ ¸å‡½æ•°", ["rbf", "linear", "poly", "sigmoid"])
top_k_values = st.sidebar.multiselect("Top-Kåˆ†æ", [50, 100, 200, 500, 1000], default=[50, 100, 200, 500])

# ä¸»è¦åŠŸèƒ½å‡½æ•°
@st.cache_data
def load_results_data(results_dir="quick_ocsvm_results"):
    """åŠ è½½å¼‚å¸¸æ£€æµ‹ç»“æœæ•°æ®"""
    try:
        # åŠ è½½ä¸»è¦ç»“æœ
        with open(os.path.join(results_dir, "quick_ocsvm_results.pkl"), 'rb') as f:
            main_results = pickle.load(f)
        
        # åŠ è½½æ‰©å±•Top-Kç»“æœ
        extended_results = None
        if os.path.exists(os.path.join(results_dir, "extended_topk_results.pkl")):
            with open(os.path.join(results_dir, "extended_topk_results.pkl"), 'rb') as f:
                extended_results = pickle.load(f)
        
        # åŠ è½½æ··æ·†çŸ©é˜µç»“æœ
        confusion_results = None
        if os.path.exists(os.path.join(results_dir, "confusion_matrix_results.pkl")):
            with open(os.path.join(results_dir, "confusion_matrix_results.pkl"), 'rb') as f:
                confusion_results = pickle.load(f)
        
        return main_results, extended_results, confusion_results
    except Exception as e:
        st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None, None

@st.cache_data
def load_csv_results(results_dir="quick_ocsvm_results"):
    """åŠ è½½CSVæ ¼å¼çš„ç»“æœæ–‡ä»¶"""
    csv_data = {}
    try:
        # åŠ è½½ä¸åŒTop-Kçš„CSVæ–‡ä»¶
        for k in [50, 100, 200, 500]:
            csv_file = os.path.join(results_dir, f"top_{k}_results.csv")
            if os.path.exists(csv_file):
                csv_data[k] = pd.read_csv(csv_file)
        
        # åŠ è½½æ··æ·†çŸ©é˜µæŠ¥å‘Š
        cm_file = os.path.join(results_dir, "confusion_matrix_report.csv")
        if os.path.exists(cm_file):
            csv_data['confusion_matrix'] = pd.read_csv(cm_file)
        
        return csv_data
    except Exception as e:
        st.error(f"âŒ CSVæ•°æ®åŠ è½½å¤±è´¥: {e}")
        return {}

def create_performance_overview(main_results, extended_results):
    """åˆ›å»ºæ€§èƒ½æ¦‚è§ˆ"""
    st.subheader("ğŸ“Š æ€§èƒ½æ¦‚è§ˆ")
    
    if main_results is None:
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½ç»“æœæ•°æ®")
        return
    
    # ä¸»è¦æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ¯ Top-100ç²¾ç¡®åº¦</h3>
            <h2 style="color: #667eea;">{:.1%}</h2>
            <p>å¼‚å¸¸æ£€æµ‹å‡†ç¡®ç‡</p>
        </div>
        """.format(main_results.get('precision_100', 0)), unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ“ˆ æ£€æµ‹å¼‚å¸¸æ•°</h3>
            <h2 style="color: #28a745;">{}</h2>
            <p>Top-100ä¸­çœŸå®å¼‚å¸¸</p>
        </div>
        """.format(main_results.get('top_100_anomaly_count', 0)), unsafe_allow_html=True)
    
    with col3:
        separation_ratio = main_results.get('error_stats', {}).get('separation_ratio', 0)
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ” åˆ†ç¦»åº¦</h3>
            <h2 style="color: #fd7e14;">{:.1f}x</h2>
            <p>å¼‚å¸¸/æ­£å¸¸è¯¯å·®æ¯”</p>
        </div>
        """.format(separation_ratio), unsafe_allow_html=True)
    
    with col4:
        total_nodes = main_results.get('true_labels_info', {}).get('total_nodes', 0)
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ“Š æ€»èŠ‚ç‚¹æ•°</h3>
            <h2 style="color: #6f42c1;">{:,}</h2>
            <p>æµ‹è¯•å›¾èŠ‚ç‚¹æ€»æ•°</p>
        </div>
        """.format(total_nodes), unsafe_allow_html=True)

def create_topk_analysis(extended_results, csv_data):
    """åˆ›å»ºTop-Kåˆ†æ"""
    st.subheader("ğŸ† Top-Kæ€§èƒ½åˆ†æ")
    
    if extended_results is None:
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½æ‰©å±•ç»“æœæ•°æ®")
        return
    
    # Top-Kæ€§èƒ½å¯¹æ¯”è¡¨æ ¼
    if 'topk_detailed_results' in extended_results:
        topk_data = extended_results['topk_detailed_results']
        
        # åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨æ ¼
        performance_data = []
        for k in sorted(topk_data.keys()):
            performance_data.append({
                'Top-K': f"Top-{k}",
                'Precision': f"{topk_data[k]['precision']:.4f}",
                'Recall': f"{topk_data[k]['recall']:.4f}",
                'F1-Score': f"{topk_data[k]['f1']:.4f}",
                'Coverage': f"{topk_data[k]['coverage']:.4f}",
                'æ£€æµ‹å¼‚å¸¸æ•°': topk_data[k]['anomaly_count']
            })
        
        df_performance = pd.DataFrame(performance_data)
        st.dataframe(df_performance, use_container_width=True)
        
        # Top-Kæ€§èƒ½è¶‹åŠ¿å›¾
        col1, col2 = st.columns(2)
        
        with col1:
            # Precisionè¶‹åŠ¿
            k_values = sorted(topk_data.keys())
            precisions = [topk_data[k]['precision'] for k in k_values]
            recalls = [topk_data[k]['recall'] for k in k_values]
            f1_scores = [topk_data[k]['f1'] for k in k_values]
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=k_values, y=precisions, mode='lines+markers', 
                                   name='Precision', line=dict(color='blue', width=3)))
            fig.add_trace(go.Scatter(x=k_values, y=recalls, mode='lines+markers', 
                                   name='Recall', line=dict(color='red', width=3)))
            fig.add_trace(go.Scatter(x=k_values, y=f1_scores, mode='lines+markers', 
                                   name='F1-Score', line=dict(color='green', width=3)))
            
            fig.update_layout(title="Top-Kæ€§èƒ½è¶‹åŠ¿", xaxis_title="Kå€¼", yaxis_title="æ€§èƒ½æŒ‡æ ‡",
                            height=400, template="plotly_white")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # æ£€æµ‹å¼‚å¸¸æ•°é‡æŸ±çŠ¶å›¾
            anomaly_counts = [topk_data[k]['anomaly_count'] for k in k_values]
            
            fig = px.bar(x=[f"Top-{k}" for k in k_values], y=anomaly_counts,
                        title="Top-Kæ£€æµ‹å¼‚å¸¸æ•°é‡", labels={'x': 'Top-K', 'y': 'å¼‚å¸¸èŠ‚ç‚¹æ•°'})
            fig.update_traces(marker_color='lightcoral')
            fig.update_layout(height=400, template="plotly_white")
            st.plotly_chart(fig, use_container_width=True)

def create_confusion_matrix_analysis(confusion_results):
    """åˆ›å»ºæ··æ·†çŸ©é˜µåˆ†æ"""
    st.subheader("ğŸ“Š æ··æ·†çŸ©é˜µåˆ†æ")
    
    if confusion_results is None:
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½æ··æ·†çŸ©é˜µæ•°æ®")
        return
    
    # æ··æ·†çŸ©é˜µæŒ‡æ ‡è¡¨æ ¼
    if 'confusion_matrices' in confusion_results:
        cm_data = confusion_results['confusion_matrices']
        
        # åˆ›å»ºæ··æ·†çŸ©é˜µè¡¨æ ¼
        cm_table_data = []
        for k in sorted(cm_data.keys()):
            cm = cm_data[k]
            cm_table_data.append({
                'Top-K': f"Top-{k}",
                'TP': cm['tp'],
                'FP': cm['fp'],
                'TN': cm['tn'],
                'FN': cm['fn'],
                'Precision': f"{cm['precision']:.4f}",
                'Recall': f"{cm['recall']:.4f}",
                'Specificity': f"{cm['specificity']:.4f}",
                'F1-Score': f"{cm['f1_score']:.4f}"
            })
        
        df_cm = pd.DataFrame(cm_table_data)
        st.dataframe(df_cm, use_container_width=True)
        
        # æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
        st.subheader("ğŸ”¥ æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾")
        
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„Kå€¼
        selected_k = st.selectbox("é€‰æ‹©Top-Kå€¼", sorted(cm_data.keys()), index=1)
        
        if selected_k in cm_data:
            cm_matrix = cm_data[selected_k]['confusion_matrix']
            
            # åˆ›å»ºçƒ­åŠ›å›¾
            fig = px.imshow(cm_matrix, 
                          labels=dict(x="é¢„æµ‹æ ‡ç­¾", y="çœŸå®æ ‡ç­¾", color="èŠ‚ç‚¹æ•°é‡"),
                          x=['é¢„æµ‹æ­£å¸¸', 'é¢„æµ‹å¼‚å¸¸'],
                          y=['çœŸå®æ­£å¸¸', 'çœŸå®å¼‚å¸¸'],
                          color_continuous_scale='Blues',
                          title=f"Top-{selected_k} æ··æ·†çŸ©é˜µ")
            
            # æ·»åŠ æ•°å€¼æ ‡æ³¨
            for i in range(len(cm_matrix)):
                for j in range(len(cm_matrix[0])):
                    fig.add_annotation(x=j, y=i, text=str(cm_matrix[i][j]),
                                     showarrow=False, font=dict(color="black", size=16))
            
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)

def create_detailed_results_view(csv_data):
    """åˆ›å»ºè¯¦ç»†ç»“æœæŸ¥çœ‹"""
    st.subheader("ğŸ“‹ è¯¦ç»†ç»“æœæŸ¥çœ‹")
    
    if not csv_data:
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½CSVæ•°æ®")
        return
    
    # é€‰æ‹©è¦æŸ¥çœ‹çš„Top-Kç»“æœ
    available_k = [k for k in [50, 100, 200, 500] if k in csv_data]
    if not available_k:
        st.error("âŒ æ²¡æœ‰æ‰¾åˆ°Top-Kç»“æœæ–‡ä»¶")
        return
    
    selected_k = st.selectbox("é€‰æ‹©Top-Kç»“æœ", available_k, key="detailed_k")
    
    if selected_k in csv_data:
        df = csv_data[selected_k]
        
        # ç»“æœç»Ÿè®¡
        col1, col2, col3 = st.columns(3)
        with col1:
            correct_count = df['is_correct'].sum()
            st.metric("âœ… æ­£ç¡®æ£€æµ‹", f"{correct_count}/{len(df)}")
        with col2:
            precision = correct_count / len(df)
            st.metric("ğŸ¯ ç²¾ç¡®åº¦", f"{precision:.1%}")
        with col3:
            avg_score = df['anomaly_score'].mean()
            st.metric("ğŸ“ˆ å¹³å‡å¼‚å¸¸åˆ†æ•°", f"{avg_score:.6f}")
        
        # è¿‡æ»¤é€‰é¡¹
        st.subheader("ğŸ” ç»“æœè¿‡æ»¤")
        col1, col2 = st.columns(2)
        
        with col1:
            show_correct_only = st.checkbox("åªæ˜¾ç¤ºæ­£ç¡®æ£€æµ‹")
            show_top_n = st.slider("æ˜¾ç¤ºå‰Nä¸ªç»“æœ", 10, len(df), min(50, len(df)))
        
        with col2:
            label_filter = st.selectbox("æ ‡ç­¾è¿‡æ»¤", ["å…¨éƒ¨", "å¼‚å¸¸", "æ­£å¸¸"])
        
        # åº”ç”¨è¿‡æ»¤
        filtered_df = df.head(show_top_n).copy()
        
        if show_correct_only:
            filtered_df = filtered_df[filtered_df['is_correct'] == True]
        
        if label_filter == "å¼‚å¸¸":
            filtered_df = filtered_df[filtered_df['true_label'] == 1]
        elif label_filter == "æ­£å¸¸":
            filtered_df = filtered_df[filtered_df['true_label'] == 0]
        
        # æ·»åŠ æ ‡ç­¾åç§°å’Œé¢„æµ‹ç»“æœåˆ—
        filtered_df['æ ‡ç­¾åç§°'] = filtered_df['true_label'].map({0: 'æ­£å¸¸', 1: 'å¼‚å¸¸'})
        filtered_df['é¢„æµ‹ç»“æœ'] = filtered_df['is_correct'].map({True: 'âœ… æ­£ç¡®', False: 'âŒ é”™è¯¯'})
        
        # é‡å‘½ååˆ—
        display_df = filtered_df[['rank', 'node_id', 'anomaly_score', 'reconstruction_error', 
                                'æ ‡ç­¾åç§°', 'é¢„æµ‹ç»“æœ']].copy()
        display_df.columns = ['æ’å', 'èŠ‚ç‚¹ID', 'å¼‚å¸¸åˆ†æ•°', 'é‡æ„è¯¯å·®', 'çœŸå®æ ‡ç­¾', 'é¢„æµ‹ç»“æœ']
        
        # æ˜¾ç¤ºè¡¨æ ¼
        st.dataframe(display_df, use_container_width=True)
        
        # ä¸‹è½½æŒ‰é’®
        csv_string = display_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½è¿‡æ»¤ç»“æœ",
            data=csv_string,
            file_name=f"top_{selected_k}_filtered_results.csv",
            mime="text/csv"
        )

def create_error_distribution_analysis(main_results):
    """åˆ›å»ºè¯¯å·®åˆ†å¸ƒåˆ†æ"""
    st.subheader("ğŸ“Š é‡æ„è¯¯å·®åˆ†å¸ƒåˆ†æ")
    
    if main_results is None:
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½ç»“æœæ•°æ®")
        return
    
    error_stats = main_results.get('error_stats', {})
    
    # è¯¯å·®ç»Ÿè®¡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        normal_mean = error_stats.get('normal_mean', 0)
        st.metric("ğŸ”µ æ­£å¸¸èŠ‚ç‚¹å¹³å‡è¯¯å·®", f"{normal_mean:.6f}")
    
    with col2:
        anomaly_mean = error_stats.get('anomaly_mean', 0)
        st.metric("ğŸ”´ å¼‚å¸¸èŠ‚ç‚¹å¹³å‡è¯¯å·®", f"{anomaly_mean:.6f}")
    
    with col3:
        separation_ratio = error_stats.get('separation_ratio', 0)
        st.metric("ğŸ“Š åˆ†ç¦»åº¦", f"{separation_ratio:.2f}x")
    
    # åˆ†ç¦»åº¦åˆ†æ
    if separation_ratio > 100:
        st.markdown("""
        <div class="status-success">
            <strong>ğŸŒŸ å®Œç¾åˆ†ç¦»!</strong> å¼‚å¸¸èŠ‚ç‚¹å’Œæ­£å¸¸èŠ‚ç‚¹çš„é‡æ„è¯¯å·®æœ‰æ˜æ˜¾åŒºåˆ«ï¼Œæ¨¡å‹æ€§èƒ½ä¼˜ç§€ã€‚
        </div>
        """, unsafe_allow_html=True)
    elif separation_ratio > 10:
        st.markdown("""
        <div class="status-success">
            <strong>âœ… è‰¯å¥½åˆ†ç¦»!</strong> å¼‚å¸¸èŠ‚ç‚¹å’Œæ­£å¸¸èŠ‚ç‚¹æœ‰è¾ƒå¥½çš„åŒºåˆ†åº¦ã€‚
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="status-warning">
            <strong>âš ï¸ åˆ†ç¦»åº¦è¾ƒä½!</strong> å¯èƒ½éœ€è¦è°ƒæ•´æ¨¡å‹å‚æ•°æˆ–ç‰¹å¾å·¥ç¨‹ã€‚
        </div>
        """, unsafe_allow_html=True)

def create_model_info():
    """åˆ›å»ºæ¨¡å‹ä¿¡æ¯é¢æ¿"""
    st.subheader("ğŸ”¬ æŠ€æœ¯æ¶æ„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **ğŸ§  GraphSAGEè‡ªç¼–ç å™¨**
        - è¾“å…¥ç»´åº¦: 4 (ä¼˜åŒ–åç‰¹å¾)
        - éšè—ç»´åº¦: 128
        - æ½œåœ¨ç»´åº¦: 64
        - Dropout: 0.2
        - æ¿€æ´»å‡½æ•°: ReLU
        """)
        
        st.markdown("""
        **ğŸ¯ OCSVMå¼‚å¸¸æ£€æµ‹**
        - æ ¸å‡½æ•°: RBF
        - Nuå‚æ•°: 0.05
        - Gamma: auto
        - ç‰¹å¾: ä»…é‡æ„è¯¯å·® (æœ€ä¼˜æ–¹æ³•)
        """)
    
    with col2:
        st.markdown("""
        **ğŸ“Š æ•°æ®é›†ä¿¡æ¯**
        - è®­ç»ƒé›†: 3ä¸ªéšæœºæ¸¸èµ°å­å›¾
        - æµ‹è¯•é›†: çœŸå®ç½‘ç»œå›¾
        - æ ‡ç­¾: é’“é±¼/å¯ç–‘ vs æ­£å¸¸èŠ‚ç‚¹
        - å¼‚å¸¸æ¯”ä¾‹: ~4.3%
        """)
        
        st.markdown("""
        **ğŸš€ æ ¸å¿ƒä¼˜åŠ¿**
        - 100% Top-100ç²¾ç¡®åº¦
        - æ— ç›‘ç£å­¦ä¹ 
        - å¯æ‰©å±•æ€§å¼º
        - é‡æ„è¯¯å·®æœ€çº¯å‡€å¼‚å¸¸ä¿¡å·
        """)

def main():
    """ä¸»å‡½æ•°"""
    # æ•°æ®åŠ è½½çŠ¶æ€
    st.sidebar.subheader("ğŸ“Š æ•°æ®çŠ¶æ€")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    results_dir = st.session_state.get('path_ç»“æœä¿å­˜ç›®å½•', 'quick_ocsvm_results')
    
    data_status = {}
    required_files = [
        'quick_ocsvm_results.pkl',
        'extended_topk_results.pkl',
        'confusion_matrix_results.pkl',
        'top_100_results.csv'
    ]
    
    for file in required_files:
        file_path = os.path.join(results_dir, file)
        data_status[file] = os.path.exists(file_path)
        
        status_icon = "âœ…" if data_status[file] else "âŒ"
        st.sidebar.text(f"{status_icon} {file}")
    
    all_files_exist = all(data_status.values())
    
    if all_files_exist:
        st.sidebar.markdown("""
        <div class="status-success">
            âœ… æ‰€æœ‰æ•°æ®æ–‡ä»¶å°±ç»ª
        </div>
        """, unsafe_allow_html=True)
    else:
        st.sidebar.markdown("""
        <div class="status-warning">
            âš ï¸ éƒ¨åˆ†æ•°æ®æ–‡ä»¶ç¼ºå¤±
        </div>
        """, unsafe_allow_html=True)
    
    # åŠ è½½æ•°æ®æŒ‰é’®
    if st.sidebar.button("ğŸ”„ åŠ è½½/åˆ·æ–°æ•°æ®", type="primary"):
        st.cache_data.clear()
        st.rerun()
    
    # ä¸»å†…å®¹åŒºåŸŸ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š æ€§èƒ½æ¦‚è§ˆ", "ğŸ† Top-Kåˆ†æ", "ğŸ“Š æ··æ·†çŸ©é˜µ", "ğŸ“‹ è¯¦ç»†ç»“æœ", "ğŸ”¬ æŠ€æœ¯ä¿¡æ¯"
    ])
    
    # åŠ è½½æ•°æ®
    main_results, extended_results, confusion_results = load_results_data(results_dir)
    csv_data = load_csv_results(results_dir)
    
    with tab1:
        create_performance_overview(main_results, extended_results)
        create_error_distribution_analysis(main_results)
    
    with tab2:
        create_topk_analysis(extended_results, csv_data)
    
    with tab3:
        create_confusion_matrix_analysis(confusion_results)
    
    with tab4:
        create_detailed_results_view(csv_data)
    
    with tab5:
        create_model_info()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem;">
        ğŸ¯ GraphSAGEå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ | åŸºäºå›¾ç¥ç»ç½‘ç»œçš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ | 
        <a href="https://github.com/your-repo" style="color: #667eea;">GitHub</a>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
